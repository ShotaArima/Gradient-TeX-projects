\subsection{研究背景}
近年，情報技術の進歩に伴い，機械学習モデルが多くの分野で活用され始めている．金融，医療，交通などの領域において，膨大なデータを解析することで効率的かつ高度な意思決定が可能となり，私たちの生活は利便性と効率性を向上させる多くの恩恵を受けられるようになった．一方で，これらのモデルに依存する場面が増えるにつれて，機械学習モデルの誤動作や悪用が引き起こすリスクも拡大している．

特に，機械学習モデルの脆弱性を悪用した攻撃手法が注目されており，その中でも敵対的サンプルによる攻撃が重要な課題となっている\cite{MBSD-AdversarialTraining}．
敵対的サンプルとは，人間には見分けのつかない微細なノイズをデータに付与することで，機械学習モデルの誤分類を引き起こすデータである\cite{MBSD-AdversarialExample}．このようなデータによる攻撃により，モデルが誤った結果を出力することで，安全性や信頼性が損なわれるだけでなく，重大な社会的・経済的影響を引き起こす可能性がある．

たとえば，自動運転車の物体認識システムに敵対的サンプルを送り込むことで，信号や歩行者を誤認し，交通事故につながるリスクがある\cite{AdversarialMachineLearning:BayesianPerspectives}．さらに，金融や医療の分野においても同様のリスクが存在する．例えば，銀行のローンの審査システムについての機械学習モデルを想定すると，本来なら認可すべきではないリスクの高いローンを誤って承認されるケースが考えられる．具体的には，敵対的サンプルを用いて信用スコアを操作することで，信用リスクの高い個人がローンを受けられるようになり，銀行の財務リスクが増大する可能性がある．また，医療分野では，患者の診断システムに敵対的サンプルを使用することで，誤った診断結果を出力し，患者の治療に重大な影響を与えるリスクがある．例えば，がんの診断システムにおいて，敵対的サンプルを用いて誤った診断を行うことで，必要な治療が遅れる可能性がある．このように，敵対的サンプルはあらゆる分野で機械学習モデルの信頼性を脅かす要因となっており，これに対処するための安全性向上が求められている．

敵対的サンプルは主に画像データを対象に研究が行われてきた．特に自動運転における物体検知の研究においてこの敵対的サンプルによる誤分類問題がよく取り上げられていru
\cite{MBSD-automobile}．画像データはピクセル単位の情報であり，ノイズを加えた場合でも人間の目にはほとんど違いが分からないため，敵対的サンプルの生成が比較的容易である．また表形式データのような特徴量の関係性などの特性を考慮する必要がないため，研究が容易な側面がある．しかし画像データだけではなく，表形式データに対する攻撃もまた無視できない課題である．表形式データは，金融，医療，ビジネス領域で広く利用されており，機械学習モデルの入力データとしても多く用いられている．表形式データは数値やカテゴリカルデータを含むため，ノイズを加える際にデータの一貫性や現実性を保つことが難しい．そのため，画像用の敵対的サンプル生成手法を適用すると非現実的なサンプルが生成される可能性がある．画像用の敵対的サンプル生成手法を適用すると非現実的なサンプルが生成される可能性がある．そのため，表形式データの敵対的サンプルの生成手法では，入力データの特性に合わせた敵対的サンプルの生成手法が求められる．

\subsection{研究目的}
上記の議論のもと，本研究では表形式データの特徴を考慮したより自然な敵対的サンプルを生成する手法を提案することを目的とする．元データの分布に合わせてより少ないノイズを加え，連続値として出力される非現実的なサンプルの問題を解決する．以上より，より自然な表形式データに対する敵対的サンプルの生成が可能となる．提案手法により，本研究の目的が達成されることで，既存の機械学習モデルの弱点をより正確に把握することが可能となる．これにより，モデルの脆弱性を評価し，敵対的サンプルによる誤分類を防ぐための対応策を事前に講じることができ，モデルの安全性向上に貢献することができる．