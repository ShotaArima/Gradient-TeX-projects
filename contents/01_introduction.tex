\subsection{研究背景}
近年，情報技術の進歩に伴い，機械学習モデルが多くの分野で活用され始めている．金融，医療，交通などの領域において，膨大なデータを解析することで効率的かつ高度な意思決定が可能となった．これにより私たちの生活は利便性と効率性を向上させる多くの恩恵を受けられるようになった．しかしながら，機械学習モデルの利用が広がる中で，それに伴う新たな脅威も顕在化している．その中でも，機械学習モデルの脆弱性を悪用する攻撃手法が注目されている．その一例として，敵対的サンプルによる攻撃が挙げられる．敵対的サンプルとは，人間には見分けのつかない微細なノイズをデータに付与することで機械学習モデルの誤分類を引き起こすデータである．このようなデータを用いた攻撃によって機械学習モデルが重大な誤りを犯す可能性がある．例えば，銀行のローンの審査システムについての機械学習モデルを想定すると，本来なら認可すべきではないリスクの高いローンを誤って承認されるケースが考えられる．このような問題に対処するため，機械学習モデルの安全性が求められており，よりノイズの小さい敵対的サンプルの生成によってよりロバストな機械学習モデルの構築の貢献し，安全性を向上に寄与すると考えられる．

敵対的サンプルは主に画像データを対象に研究が行われてきた．特に自動運転における物体検知の研究においてこの敵対的サンプルによる誤分類問題がよく取り上げられていた．しかし画像データだけではなく，表形式データに対する攻撃もまた無視できない課題である．表形式データは，金融，医療，ビジネス領域で広く利用されており，機械学習モデルの入力データとしても多く用いられている．画像用の敵対的サンプル生成手法を適用すると非現実的なサンプルが生成される可能性がある．そのため，表形式データの敵対的サンプルの生成手法では，入力データの特性に合わせた敵対的サンプルの生成手法が求められる．

\subsection{研究目的}
上記の議論のもと本研究では，表形式データの特徴を考慮したより自然な敵対的サンプルを生成する手法を提案することを目的とする．元データの分布に合わせてより少ないノイズを加え，連続値として出力される非現実的なサンプルの問題を解決する．以上より，より自然な表形式データに対する敵対的サンプルの生成が可能となる．提案手法により，本研究の目的が達成されることで，既存の機械学習モデルの弱点をより正確に把握することが可能となる．これにより，モデルの脆弱性を評価し，敵対的サンプルによる誤分類を防ぐための対応策を事前に講じることができ，モデルの安全性向上に貢献することができる．