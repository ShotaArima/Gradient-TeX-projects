\subsection{研究背景}
近年，情報技術の進歩に伴い，機械学習モデルが多くの分野で活用され始めている．金融，医療，交通などの領域において，膨大なデータを解析することで効率的かつ高度な意思決定が可能となり，私たちの生活は利便性と効率性を向上させる多くの恩恵を受けられるようになった．一方で，これらのモデルに依存する場面が増えるにつれて，機械学習モデルの誤動作や悪用が引き起こすリスクも拡大している．

特に，機械学習モデルの脆弱性を悪用した攻撃手法が注目されており，その中でも敵対的サンプルによる攻撃が重要な課題となっている．\cite{MBSD-AdversarialTraining}
敵対的サンプルとは，人間には見分けのつかない微細なノイズをデータに付与することで，機械学習モデルの誤分類を引き起こすデータである．\cite{MBSD-AdversarialExample}このようなデータによる攻撃により，モデルが誤った結果を出力することで，安全性や信頼性が損なわれるだけでなく，重大な社会的・経済的影響を引き起こす可能性がある．たとえば，自動運転車の物体認識システムに敵対的サンプルを送り込むことで，信号や歩行者を誤認し，交通事故につながるリスクがある．\cite{AdversarialMachineLearning:BayesianPerspectives}

さらに，金融や医療の分野においても同様のリスクが存在する．例えば，銀行のローンの審査システムについての機械学習モデルを想定すると，本来なら認可すべきではないリスクの高いローンを誤って承認されるケースが考えられる．このように，敵対的サンプルはあらゆる分野で機械学習モデルの信頼性を脅かす要因となっており，これに対処するための安全性向上が求められている．

一方で，これらのモデルに依存する場面が増えるにつれて，機械学習モデルの誤動作や悪用が引き起こすリスクも拡大している．特に，機械学習モデルの脆弱性を悪用した攻撃手法が注目されており，その中でも敵対的サンプルによる攻撃が重要な課題となっている．
敵対的サンプルとは，人間には見分けのつかない微細なノイズをデータに付与することで，機械学習モデルの誤分類を引き起こすデータである．このような攻撃により，モデルが誤った結果を出力することで，安全性や信頼性が損なわれるだけでなく，重大な社会的・経済的影響を引き起こす可能性がある．例えば，自動運転車の物体認識システムに敵対的サンプルを送り込むことで，信号や歩行者を誤認し，交通事故につながるリスクがある．さらに，金融や医療の分野においても同様のリスクが存在する．例えば，銀行のローンの審査システムについての機械学習モデルを想定すると，本来なら認可すべきではないリスクの高いローンを誤って承認されるケースが考えられる．このように，敵対的サンプルはあらゆる分野で機械学習モデルの信頼性を脅かす要因となっており，これに対処するための安全性向上が求められている．

このような問題に対処するため，機械学習モデルの安全性が求められており，よりノイズの小さい敵対的サンプルの生成によってよりロバストな機械学習モデルの構築の貢献し，安全性を向上に寄与すると考えられる．

敵対的サンプルは主に画像データを対象に研究が行われてきた．特に自動運転における物体検知の研究\cite{MBSD-automobile}においてこの敵対的サンプルによる誤分類問題がよく取り上げられていた．しかし画像データだけではなく，表形式データに対する攻撃もまた無視できない課題である．表形式データは，金融，医療，ビジネス領域で広く利用されており，機械学習モデルの入力データとしても多く用いられている．画像用の敵対的サンプル生成手法を適用すると非現実的なサンプルが生成される可能性がある．そのため，表形式データの敵対的サンプルの生成手法では，入力データの特性に合わせた敵対的サンプルの生成手法が求められる．

\subsection{研究目的}
上記の議論のもと本研究では，表形式データの特徴を考慮したより自然な敵対的サンプルを生成する手法を提案することを目的とする．元データの分布に合わせてより少ないノイズを加え，連続値として出力される非現実的なサンプルの問題を解決する．以上より，より自然な表形式データに対する敵対的サンプルの生成が可能となる．提案手法により，本研究の目的が達成されることで，既存の機械学習モデルの弱点をより正確に把握することが可能となる．これにより，モデルの脆弱性を評価し，敵対的サンプルによる誤分類を防ぐための対応策を事前に講じることができ，モデルの安全性向上に貢献することができる．